# Architecture des Donn√©es - Medallion (Bronze/Silver/Gold)

**Projet MSPR TPRE813 - EPSI 2026**

## Vue d'Ensemble

Ce projet adopte l'**architecture Medallion** (aussi appel√©e Bronze/Silver/Gold), standard de l'industrie en Data Engineering moderne, popularis√©e par Databricks et largement utilis√©e dans les plateformes Big Data (Snowflake, Delta Lake, Azure Synapse).

### Principes Fondamentaux

```
ü•â Bronze ‚Üí ü•à Silver ‚Üí ü•á Gold
(Source)   (Nettoy√©)   (Agr√©g√©/ML)
```

Chaque couche a une **responsabilit√© unique** et des **garanties de qualit√©** sp√©cifiques, permettant une tra√ßabilit√© compl√®te du pipeline de donn√©es.

---

## ü•â Couche Bronze - Donn√©es Brutes

**Localisation** : `data/bronze/`

**R√¥le** : Zone de landing pour donn√©es sources, **immuables apr√®s t√©l√©chargement**

### Caract√©ristiques

- **Format** : Original (CSV, XLSX, JSON, ZIP)
- **Transformations** : AUCUNE - Donn√©es "as-is"
- **Qualit√©** : Aucune garantie (peut contenir erreurs, doublons, valeurs manquantes)
- **Acc√®s** : Read-only apr√®s t√©l√©chargement initial
- **Tra√ßabilit√©** : URL source + date de t√©l√©chargement document√©es

### Fichiers Pr√©sents

| Fichier | Taille | Source | Description | T√©l√©charg√© |
|---------|--------|--------|-------------|------------|
| `elections_agregees_1999_2024.csv` | 2.2 GB | data.gouv.fr | R√©sultats √©lections 1999-2024 | 10/02/2026 |
| `revenus_commune.csv` | 4.8 MB | INSEE | Revenus fiscaux par commune | 10/02/2026 |
| `referentiel_communes.csv` | 2.5 MB | INSEE | R√©f√©rentiel 37.5K communes France | 10/02/2026 |
| `population_historique_1968_2022/` | 43.6 MB | INSEE | Population par √¢ge 1968-2022 | 10/02/2026 |
| `diplomes_formation_2022/` | 66 MB | INSEE | Niveaux dipl√¥mes par commune | 10/02/2026 |
| `csp_actifs_2554/` | 28.5 MB | INSEE | CSP actifs 25-54 ans | 10/02/2026 |

**Total Bronze** : ~2.36 GB

### Notebook Responsable

- **`01_data_download.ipynb`** : T√©l√©chargement depuis sources publiques

### R√®gles de Gestion Bronze

- ‚ùå **JAMAIS modifier** un fichier Bronze apr√®s t√©l√©chargement
- ‚úÖ Re-t√©l√©charger si source mise √† jour (versionner: `elections_2024.csv`, `elections_2025.csv`)
- ‚úÖ Garder ZIP originaux si n√©cessaire pour tra√ßabilit√©
- ‚úÖ Documenter m√©tadonn√©es : URL source, date t√©l√©chargement, hash MD5

---

## ü•à Couche Silver - Donn√©es Nettoy√©es

**Localisation** : `data/silver/`

**R√¥le** : Donn√©es valid√©es, typ√©es, converties en format optimis√© Parquet

### Caract√©ristiques

- **Format** : Parquet (compression snappy, engine pyarrow)
- **Transformations** : Parsing, typage, filtrage, d√©duplication
- **Qualit√©** : Donn√©es valid√©es, tests qualit√© pass√©s
- **Acc√®s** : Read/Write (peut √™tre r√©g√©n√©r√© depuis Bronze)
- **Performance** : 10-100x plus rapide que CSV

### Transformations Appliqu√©es

1. ‚úÖ **Parsing correct** :
   - S√©parateurs CSV (`;` pour fichiers fran√ßais)
   - Skiprows pour m√©tadonn√©es INSEE (lignes 0-4)
   
2. ‚úÖ **Types de donn√©es coh√©rents** :
   ```python
   dtype={
       'code_commune': str,      # Codes INSEE en string (garder leading zeros)
       'code_departement': str,
       'annee': int,
       'population': int,
       'revenus_median': float
   }
   ```

3. ‚úÖ **Filtrage g√©ographique** :
   - Petite Couronne : 144 communes (75, 92, 93, 94)
   - Suppression codes sp√©ciaux (COM, arrondissements municipaux)

4. ‚úÖ **Conversion Parquet** :
   - Compression `snappy` (bon compromis vitesse/taille)
   - Engine `pyarrow` (performance optimale)

5. ‚úÖ **Qualit√© donn√©es** :
   - Suppression doublons
   - Identification valeurs manquantes
   - D√©tection valeurs aberrantes (outliers)

6. ‚úÖ **Normalisation colonnes** :
   - Noms colonnes en `snake_case`
   - Suppression accents et caract√®res sp√©ciaux
   - Colonnes coh√©rentes entre datasets

### Fichiers Attendus

| Fichier | Description | Lignes | Colonnes | Taille |
|---------|-------------|--------|----------|--------|
| `referentiel_petite_couronne.parquet` | 144 communes PC | 144 | 10 | 4.8 KB |
| `elections_petite_couronne.parquet` | √âlections filtr√©es 75/92/93/94 | ~2M | 18 | ~40 MB |
| `revenus_petite_couronne.parquet` | Revenus 144 communes | 144 | 15 | ~15 KB |
| `population_petite_couronne.parquet` | Population par √¢ge | 144 | 50 | ~50 KB |
| `diplomes_petite_couronne.parquet` | Niveaux dipl√¥mes | 144 | 60 | ~60 KB |
| `csp_petite_couronne.parquet` | CSP actifs | 144 | 30 | ~30 KB |

**Total Silver** : ~50 MB (compression 98% vs Bronze !)

### Notebooks Responsables

- **`02_exploration.ipynb`** : Exploration initiale + premiers exports Silver
- **`03_etl.ipynb`** : ETL complet Bronze ‚Üí Silver

### R√®gles de Gestion Silver

- ‚úÖ Peut √™tre **r√©g√©n√©r√© depuis Bronze** √† tout moment (idempotence)
- ‚úÖ Ajouter m√©tadonn√©es Parquet :
  ```python
  df.to_parquet(
      path,
      metadata={
          'source': 'elections_agregees_1999_2024.csv',
          'transformation_date': '2026-02-13',
          'code_version': 'v1.2.3'
      }
  )
  ```
- ‚úÖ Tests qualit√© obligatoires :
  - Valeurs manquantes < 5% par colonne
  - Pas de doublons sur cl√© primaire (code_commune)
  - Types de donn√©es coh√©rents
- ‚úÖ Documenter transformations appliqu√©es (notebook + commentaires)

---

## ü•á Couche Gold - Donn√©es Agr√©g√©es / ML-Ready

**Localisation** : `data/gold/`

**R√¥le** : Tables finales pour analyse m√©tier, visualisations et Machine Learning

### Caract√©ristiques

- **Format** : Parquet + JSON (m√©triques) + CSV (exports client)
- **Transformations** : Jointures, features engineering, agr√©gations temporelles
- **Qualit√©** : Business-ready, document√©, versionn√©
- **Acc√®s** : Read/Write (outputs ML, pr√©dictions)
- **Usage** : Dashboards, mod√®les ML, livrables client

### Transformations Appliqu√©es

1. ‚úÖ **Jointures multi-sources** :
   ```
   referentiel_petite_couronne
   ‚îú‚îÄ‚îÄ LEFT JOIN elections (sur code_commune)
   ‚îú‚îÄ‚îÄ LEFT JOIN revenus (sur code_commune)
   ‚îú‚îÄ‚îÄ LEFT JOIN population (sur code_commune)
   ‚îú‚îÄ‚îÄ LEFT JOIN diplomes (sur code_commune)
   ‚îî‚îÄ‚îÄ LEFT JOIN csp (sur code_commune)
   = dataset_ml_complet
   ```

2. ‚úÖ **Features Engineering** :
   - **Ratios** : `taux_chomage = chomeurs / actifs`
   - **Tendances** : √âvolution population 2015-2022 (croissance/d√©clin)
   - **Indicateurs composites** : Indice de pr√©carit√©, diversit√© socio-√©conomique
   - **Variables cat√©gorielles** : Encoding one-hot (parti politique dominant)

3. ‚úÖ **Agr√©gations temporelles** :
   - Moyennes glissantes 3 ans (lissage fluctuations)
   - √âvolutions annuelles (taux de croissance)
   - Lag features (valeurs ann√©e N-1, N-2, N-3)

4. ‚úÖ **Dataset ML** :
   - Split train/test (80/20)
   - Normalisation features (StandardScaler)
   - Gestion valeurs manquantes (imputation m√©diane)

5. ‚úÖ **Pr√©dictions & R√©sultats** :
   - Pr√©visions √©lectorales 2027
   - Scores importance features
   - M√©triques performance (RMSE, R¬≤, MAE)

### Fichiers Attendus

| Fichier | Description | Usage | Format |
|---------|-------------|-------|--------|
| `dataset_ml_complet.parquet` | Features + target jointur√©es | Training ML | Parquet |
| `dataset_train.parquet` | 80% donn√©es (training set) | Entra√Ænement mod√®le | Parquet |
| `dataset_test.parquet` | 20% donn√©es (validation) | √âvaluation mod√®le | Parquet |
| `predictions_2027.parquet` | Pr√©visions √©lectorales 2027 | Livrable client | Parquet |
| `features_importance.parquet` | Importance variables | Interpr√©tabilit√© | Parquet |
| `metriques_modele.json` | Scores (RMSE, R¬≤, MAE) | Reporting | JSON |
| `export_client_2027.csv` | Pr√©dictions format CSV | Livrable client | CSV |

**Total Gold** : ~10 MB

### Notebooks Responsables

- **`04_features.ipynb`** : Features engineering Silver ‚Üí Gold
- **`05_modeling.ipynb`** : Entra√Ænement mod√®les ML
- **`06_predictions.ipynb`** : G√©n√©ration pr√©visions 2027

### R√®gles de Gestion Gold

- ‚úÖ Documenter **chaque feature** engineer√©e :
  ```python
  # Feature: Indice de pr√©carit√© (0-100)
  # Formule: (taux_chomage*0.4 + taux_pauvrete*0.4 + taux_sans_diplome*0.2) * 100
  # Source: INSEE + m√©thodologie interne
  df['indice_precarite'] = (
      df['taux_chomage'] * 0.4 + 
      df['taux_pauvrete'] * 0.4 + 
      df['taux_sans_diplome'] * 0.2
  ) * 100
  ```

- ‚úÖ **Versionner mod√®les ML** :
  ```
  models/
  ‚îú‚îÄ‚îÄ model_v1_20260213.pkl  # Random Forest baseline
  ‚îú‚îÄ‚îÄ model_v2_20260220.pkl  # XGBoost optimis√©
  ‚îî‚îÄ‚îÄ model_v3_20260227.pkl  # Ensemble voting
  ```

- ‚úÖ **Exporter m√©triques** pour chaque run :
  ```json
  {
    "model": "RandomForestRegressor",
    "date": "2026-02-13",
    "hyperparameters": {"n_estimators": 100, "max_depth": 10},
    "metrics": {
      "rmse": 0.082,
      "r2": 0.76,
      "mae": 0.061
    }
  }
  ```

- ‚úÖ **Tra√ßabilit√© compl√®te** : Quel mod√®le a g√©n√©r√© quelles pr√©dictions ?

---

## Flux de Donn√©es Complet

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              01_data_download.ipynb                      ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  data.gouv.fr ‚îÄ‚îÄ‚îê                                       ‚îÇ
‚îÇ  INSEE.fr ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚ñ∫ ü•â data/bronze/ (2.36 GB)         ‚îÇ
‚îÇ  Sources API ‚îÄ‚îÄ‚îÄ‚îò     ‚Ä¢ Format original (CSV, XLSX)    ‚îÇ
‚îÇ                       ‚Ä¢ Donn√©es immuables                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      02_exploration.ipynb + 03_etl.ipynb                 ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Parsing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                        ‚îÇ
‚îÇ  Typage ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚ñ∫ ü•à data/silver/ (~50 MB)           ‚îÇ
‚îÇ  Filtrage ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚Ä¢ Format Parquet optimis√©         ‚îÇ
‚îÇ  D√©duplication       ‚Ä¢ 144 communes Petite Couronne     ‚îÇ
‚îÇ  Validation          ‚Ä¢ Types valid√©s, qualit√© contr√¥l√©e ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Fichiers g√©n√©r√©s:                                       ‚îÇ
‚îÇ  ‚Ä¢ referentiel_petite_couronne.parquet                   ‚îÇ
‚îÇ  ‚Ä¢ elections_petite_couronne.parquet                     ‚îÇ
‚îÇ  ‚Ä¢ revenus/population/diplomes/csp.parquet               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  04_features + 05_modeling + 06_predictions              ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Jointures ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                     ‚îÇ
‚îÇ  Features ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚ñ∫ ü•á data/gold/ (~10 MB)          ‚îÇ
‚îÇ  ML Training ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚Ä¢ Tables business-ready        ‚îÇ
‚îÇ  Pr√©dictions            ‚Ä¢ Features ML engineer√©es       ‚îÇ
‚îÇ                         ‚Ä¢ R√©sultats & m√©triques         ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  Fichiers g√©n√©r√©s:                                       ‚îÇ
‚îÇ  ‚Ä¢ dataset_ml_complet.parquet                            ‚îÇ
‚îÇ  ‚Ä¢ dataset_train/test.parquet                            ‚îÇ
‚îÇ  ‚Ä¢ predictions_2027.parquet                              ‚îÇ
‚îÇ  ‚Ä¢ metriques_modele.json                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Avantages Architecture Medallion

### ‚úÖ Tra√ßabilit√© Compl√®te

- **Bronze** : Source de v√©rit√© immuable (audit trail)
- **Silver** : Transformations document√©es et reproductibles
- **Gold** : R√©sultats tra√ßables jusqu'√† la source

**Exemple** : Une pr√©diction √©lectorale anormale peut √™tre retrac√©e :
```
Pr√©diction Gold ‚Üí Feature Silver ‚Üí Donn√©e Bronze ‚Üí URL source INSEE
```

### ‚úÖ S√©paration des Responsabilit√©s

Chaque couche a un **r√¥le unique** :
- **Bronze** : Ingestion simple, pas de logique m√©tier
- **Silver** : Qualit√© donn√©es (Data Quality checks)
- **Gold** : Business logic et ML

**Avantage** : Bugs isol√©s, debugging facilit√©, maintenabilit√© accrue

### ‚úÖ Performance Optimale

| Couche | Format | Taille | Temps lecture (100K lignes) |
|--------|--------|--------|----------------------------|
| Bronze | CSV | 2.36 GB | 8-12 secondes |
| Silver | Parquet | 50 MB | 0.3-0.5 secondes |
| Gold | Parquet | 10 MB | 0.1-0.2 secondes |

**Compression** : Bronze 2.36 GB ‚Üí Silver 50 MB ‚Üí Gold 10 MB (99.6% r√©duction !)

### ‚úÖ Scalabilit√©

M√™me code fonctionne pour :
- **POC** : 144 communes Petite Couronne
- **Production** : 35 000 communes France enti√®re

**Techniques** :
- Partitionnement Parquet (par d√©partement, r√©gion)
- Chunked reading (traitement par blocs)
- Dask/Spark si volume > 100 GB

### ‚úÖ Reproductibilit√©

**Pipeline lin√©aire** : Bronze ‚Üí Silver ‚Üí Gold

Ex√©cution dans l'ordre **garantit r√©sultats identiques** :
```bash
# Re-cr√©er tout le pipeline
jupyter nbconvert --execute 01_data_download.ipynb
jupyter nbconvert --execute 02_exploration.ipynb
jupyter nbconvert --execute 03_etl.ipynb
jupyter nbconvert --execute 04_features.ipynb
jupyter nbconvert --execute 05_modeling.ipynb
jupyter nbconvert --execute 06_predictions.ipynb
```

### ‚úÖ √âvolution & Maintenance

**Ajout nouvelle source** :
1. T√©l√©charger dans Bronze (01_download)
2. Parser/nettoyer dans Silver (03_etl)
3. Joindre dans Gold (04_features)

**Modification transformation** :
- Changer code Silver ‚Üí Re-run 03_etl ‚Üí Silver r√©g√©n√©r√©
- Bronze non impact√© (immuable)
- Gold automatiquement mis √† jour au prochain run

---

## Acc√®s aux Donn√©es dans Notebooks

### Import Configuration

```python
# En d√©but de chaque notebook (apr√®s imports pandas/numpy)
import sys
sys.path.append('..')
from config import DATA_BRONZE, DATA_SILVER, DATA_GOLD

# V√©rifier chemins
print(f"ü•â Bronze: {DATA_BRONZE}")
print(f"ü•à Silver: {DATA_SILVER}")
print(f"ü•á Gold: {DATA_GOLD}")
```

### Lecture Bronze (CSV)

```python
import pandas as pd

# Lecture CSV avec parsing correct
df_elections = pd.read_csv(
    DATA_BRONZE / "elections_agregees_1999_2024.csv",
    sep=";",  # S√©parateur point-virgule
    dtype={'code_commune': str, 'code_departement': str},  # Types explicites
    chunksize=10000  # Lecture par blocs si volumineux
)

# Lecture Excel INSEE avec skiprows
df_population = pd.read_excel(
    DATA_BRONZE / "population_historique_1968_2022/pop-16ans-dipl6822.xlsx",
    engine='openpyxl',
    skiprows=5  # Sauter m√©tadonn√©es INSEE
)
```

### √âcriture Silver (Parquet)

```python
# Conversion CSV ‚Üí Parquet optimis√©
df_elections_clean.to_parquet(
    DATA_SILVER / "elections_petite_couronne.parquet",
    engine='pyarrow',
    compression='snappy',
    index=False
)

print(f"‚úÖ Silver cr√©√© : {DATA_SILVER / 'elections_petite_couronne.parquet'}")
```

### Lecture Silver (Parquet)

```python
# Lecture Parquet ultra-rapide
df = pd.read_parquet(DATA_SILVER / "elections_petite_couronne.parquet")

# Lecture colonnes sp√©cifiques (performance)
df_subset = pd.read_parquet(
    DATA_SILVER / "elections_petite_couronne.parquet",
    columns=['code_commune', 'annee', 'voix', 'nuance']
)
```

### √âcriture Gold (R√©sultats ML)

```python
# Export pr√©dictions
df_predictions.to_parquet(
    DATA_GOLD / "predictions_2027.parquet",
    compression="snappy"
)

# Export m√©triques JSON
import json
metrics = {
    'model': 'RandomForest',
    'date': '2026-02-13',
    'rmse': 0.082,
    'r2': 0.76
}
with open(DATA_GOLD / "metriques_modele.json", 'w') as f:
    json.dump(metrics, f, indent=2)

# Export CSV client
df_predictions.to_csv(
    DATA_GOLD / "export_client_2027.csv",
    index=False,
    encoding='utf-8'
)
```

---

## Tests Qualit√© Donn√©es

### Silver Layer - Data Quality Checks

```python
def validate_silver_quality(df, name):
    """Tests qualit√© obligatoires couche Silver"""
    print(f"\nüîç Validation qualit√© : {name}")
    
    issues = []
    
    # Test 1: Valeurs manquantes < 5%
    missing_pct = (df.isnull().sum() / len(df)) * 100
    high_missing = missing_pct[missing_pct > 5]
    if len(high_missing) > 0:
        issues.append(f"‚ùå Colonnes avec >5% manquants: {list(high_missing.index)}")
    else:
        print("‚úÖ Valeurs manquantes OK (< 5% par colonne)")
    
    # Test 2: Pas de doublons sur cl√© primaire
    if 'code_commune' in df.columns:
        duplicates = df['code_commune'].duplicated().sum()
        if duplicates > 0:
            issues.append(f"‚ùå {duplicates} doublons sur code_commune")
        else:
            print("‚úÖ Pas de doublons sur code_commune")
    
    # Test 3: Types coh√©rents
    expected_types = {
        'code_commune': 'object',  # string
        'population': 'int64',
        'revenus_median': 'float64'
    }
    for col, expected_type in expected_types.items():
        if col in df.columns and df[col].dtype != expected_type:
            issues.append(f"‚ùå {col}: type {df[col].dtype} != attendu {expected_type}")
    
    if not issues:
        print("‚úÖ VALIDATION R√âUSSIE")
        return True
    else:
        print("‚ö†Ô∏è  PROBL√àMES D√âTECT√âS:")
        for issue in issues:
            print(f"  {issue}")
        return False

# Utilisation
validate_silver_quality(df_elections_clean, "elections_petite_couronne")
```

---

## R√©f√©rences

### Documentation Officielle

- [Databricks - Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [Delta Lake - Best Practices](https://docs.delta.io/latest/best-practices.html)
- [Snowflake - Multi-Tier Data Architecture](https://www.snowflake.com/guides/multi-tier-data-architecture)
- [Azure Synapse - Lakehouse Architecture](https://learn.microsoft.com/en-us/azure/synapse-analytics/)

### Livres Recommand√©s

- **"Data Engineering with Python"** - Paul Crickard (O'Reilly, 2023)
- **"Designing Data-Intensive Applications"** - Martin Kleppmann (O'Reilly, 2017)
- **"The Data Warehouse Toolkit"** - Ralph Kimball (Wiley, 2013)

### Articles & Blogs

- [Databricks Blog - Delta Lake Architecture](https://www.databricks.com/blog)
- [Towards Data Science - Medallion Architecture](https://towardsdatascience.com)

---

**Document cr√©√© le** : 13 f√©vrier 2026  
**Auteur** : Projet MSPR TPRE813 - EPSI 2026  
**Version** : 1.0
