# MSPR Big Data - PrÃ©diction Ã‰lectorale

**Projet EPSI - BLOC 3 RNCP35584**  
Analyse prÃ©dictive des tendances Ã©lectorales avec Apache Spark

## ğŸ“Š Objectif

DÃ©velopper un modÃ¨le prÃ©dictif pour anticiper les rÃ©sultats Ã©lectoraux Ã  1-3 ans en utilisant des indicateurs socio-Ã©conomiques (sÃ©curitÃ©, emploi, dÃ©mographie, pauvretÃ©, Ã©conomie locale).

## ğŸ¯ PÃ©rimÃ¨tre

**Zone gÃ©ographique :** Petite Couronne parisienne (Paris 75, Hauts-de-Seine 92, Seine-Saint-Denis 93, Val-de-Marne 94)  
**Volume :** ~150 communes  
**Extensible :** Architecture scalable pour toute la France (~35,000 communes)

## ğŸ“ Structure du Projet

```
mspr-813/
â”œâ”€â”€ data/                              # ğŸ—„ï¸ DonnÃ©es (non versionnÃ©es Git)
â”‚   â”œâ”€â”€ raw/                           # DonnÃ©es sources tÃ©lÃ©chargÃ©es
â”‚   â”‚   â”œâ”€â”€ elections_agregees_1999_2024.csv    # 2.2 GB - Variable cible
â”‚   â”‚   â”œâ”€â”€ revenus_commune.csv                 # 4.8 MB - Indicateur Ã©conomique
â”‚   â”‚   â”œâ”€â”€ referentiel_communes.csv            # 3 MB - ClÃ© de jointure
â”‚   â”‚   â”œâ”€â”€ population_historique_1968_2022/    # 40 MB - Dynamique dÃ©mographique
â”‚   â”‚   â”œâ”€â”€ diplomes_formation_2022/            # 81 MB - Niveau Ã©ducation
â”‚   â”‚   â”œâ”€â”€ csp_actifs_2554/                    # 28.5 MB - CatÃ©gories socio-pro
â”‚   â”‚   â””â”€â”€ ...autres datasets Phase 2...
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                     # DonnÃ©es transformÃ©es (Parquet optimisÃ© Spark)
â”‚   â”‚   â”œâ”€â”€ elections_clean.parquet            # Ã‰lections nettoyÃ©es + filtrÃ©es
â”‚   â”‚   â”œâ”€â”€ socio_eco_features.parquet         # Features engineerÃ©es
â”‚   â”‚   â””â”€â”€ master_dataset.parquet             # Dataset final jointurÃ©
â”‚   â”‚
â”‚   â””â”€â”€ output/                        # RÃ©sultats finaux
â”‚       â”œâ”€â”€ predictions_2027.csv               # PrÃ©dictions gÃ©nÃ©rÃ©es
â”‚       â””â”€â”€ model_metrics.json                 # MÃ©triques de performance
â”‚
â”œâ”€â”€ notebooks/                         # ğŸ““ Notebooks Jupyter (dÃ©veloppement interactif)
â”‚   â”œâ”€â”€ 00_setup_spark.ipynb           # âœ… Validation environnement Spark
â”‚   â”œâ”€â”€ 01_data_download.ipynb         # â¬‡ï¸ TÃ©lÃ©chargement datasets (Phase 1 + Phase 2)
â”‚   â”œâ”€â”€ 02_exploration.ipynb           # ğŸ” EDA - Analyse exploratoire (Ã€ CRÃ‰ER)
â”‚   â”œâ”€â”€ 03_etl_spark.ipynb             # ğŸ”„ Pipeline ETL avec PySpark (Ã€ CRÃ‰ER)
â”‚   â”œâ”€â”€ 04_feature_engineering.ipynb   # ğŸ› ï¸ CrÃ©ation features prÃ©dictives (Ã€ CRÃ‰ER)
â”‚   â”œâ”€â”€ 05_modeling.ipynb              # ğŸ¤– EntraÃ®nement modÃ¨les ML (Ã€ CRÃ‰ER)
â”‚   â””â”€â”€ 06_evaluation.ipynb            # ğŸ“Š Ã‰valuation et visualisations (Ã€ CRÃ‰ER)
â”‚
â”œâ”€â”€ outputs/                           # ğŸ“ˆ Exports pour soutenance
â”‚   â””â”€â”€ figures/                       # Graphiques et visualisations
â”‚       â”œâ”€â”€ correlation_matrix.png
â”‚       â”œâ”€â”€ feature_importance.png
â”‚       â””â”€â”€ predictions_map.html       # Carte interactive
â”‚
â”œâ”€â”€ docs/                              # ğŸ“š Documentation projet
â”‚   â”œâ”€â”€ ARCHITECTURE.md                # Architecture dÃ©taillÃ©e et choix techniques
â”‚   â”œâ”€â”€ DATASETS.md                    # Liste exhaustive datasets avec mÃ©tadonnÃ©es
â”‚   â”œâ”€â”€ DOWNLOAD_PRIORITY.md           # StratÃ©gie tÃ©lÃ©chargement par phases
â”‚   â””â”€â”€ URLS_DATASETS.md               # URLs de tÃ©lÃ©chargement corrigÃ©es
â”‚
â”œâ”€â”€ Dockerfile                         # ğŸ³ Image Docker Python + Spark + Java 21
â”œâ”€â”€ docker-compose.yml                 # Orchestration conteneur Jupyter Lab
â”œâ”€â”€ requirements.txt                   # DÃ©pendances Python (PySpark, scikit-learn, viz)
â””â”€â”€ README.md                          # Ce fichier
```

## ğŸ—ï¸ Organisation et Architecture

### Principe de l'organisation

Le projet suit une **architecture en couches** typique d'un projet Big Data :

1. **Couche DonnÃ©es (`data/`)** : SÃ©paration claire entre donnÃ©es brutes (immuables), transformÃ©es (optimisÃ©es), et rÃ©sultats
2. **Couche Traitement (`notebooks/`)** : Pipeline sÃ©quentiel de notebooks pour traÃ§abilitÃ© et reproductibilitÃ©
3. **Couche PrÃ©sentation (`outputs/`)** : Exports prÃªts pour soutenance
4. **Couche Infrastructure** : Docker pour isolation et reproductibilitÃ© environnement

### Pourquoi cette structure ?

#### âœ… **SÃ©paration raw/processed/output**
- **`raw/`** : DonnÃ©es sources **jamais modifiÃ©es** â†’ reproductibilitÃ© garantie
- **`processed/`** : Format **Parquet** â†’ 10x plus rapide que CSV avec Spark, compression efficace
- **`output/`** : RÃ©sultats finaux **isolÃ©s** pour faciliter export/partage

#### âœ… **Notebooks numÃ©rotÃ©s**
- **Ordre d'exÃ©cution clair** : 00 â†’ 01 â†’ 02 â†’ ... 
- **Pipeline modulaire** : chaque Ã©tape = 1 notebook
- **DÃ©veloppement itÃ©ratif** : retour en arriÃ¨re facile
- **Documentation intÃ©grÃ©e** : code + explications + rÃ©sultats

#### âœ… **Format Parquet pour Big Data**
- **Columnar storage** : lecture optimisÃ©e pour analyses (vs CSV row-based)
- **Compression automatique** : 5-10x moins d'espace disque
- **Types de donnÃ©es prÃ©servÃ©s** : pas de parsing Ã  chaque lecture
- **Partitionnement possible** : scalabilitÃ© 150 communes â†’ 35K communes

### Approche Progressive : Phase 1 â†’ Phase 2

Le projet est conÃ§u pour **progression par Ã©tapes** :

| Phase | PÃ©rimÃ¨tre | Datasets | Volume | Objectif |
|-------|-----------|----------|--------|----------|
| **Phase 1 - POC** | Petite Couronne (150 communes) | Socio-Ã©conomiques essentiels | ~2.4 GB | Valider modÃ¨le de base |
| **Phase 2 - Extension** | France entiÃ¨re (35K communes) | + Territorial (finances, environnement) | +140 MB | DÃ©montrer scalabilitÃ© |

**Phase 1** = DÃ©veloppement rapide avec variables de rÃ©fÃ©rence (revenus, CSP, diplÃ´mes)  
**Phase 2** = Extension testÃ©e pour soutenance ("architecture pensÃ©e Big Data")

ğŸ“– **Pour plus de dÃ©tails** : voir [ARCHITECTURE.md](docs/ARCHITECTURE.md)

## ğŸš€ Workflow de DÃ©veloppement

### Installation et DÃ©marrage

```bash
# 1. Cloner le projet
git clone <repo-url>
cd mspr-813

# 2. Lancer l'environnement Docker
docker-compose up -d

# 3. AccÃ©der Ã  Jupyter Lab
# Ouvrir : http://localhost:8888
```

### Pipeline d'ExÃ©cution des Notebooks

ExÃ©cuter dans l'ordre :

```
00_setup_spark.ipynb        â†’ Valider installation Spark âœ…
01_data_download.ipynb      â†’ TÃ©lÃ©charger datasets Phase 1 (+ Phase 2 si besoin)
02_exploration.ipynb        â†’ Explorer et comprendre les donnÃ©es
03_etl_spark.ipynb          â†’ Nettoyer, transformer, joindre avec PySpark
04_feature_engineering.ipynb â†’ CrÃ©er variables prÃ©dictives
05_modeling.ipynb           â†’ EntraÃ®ner modÃ¨les ML
06_evaluation.ipynb         â†’ Ã‰valuer performance et visualiser
```

### ArrÃªt de l'Environnement

```bash
docker-compose down
```

## ğŸ› ï¸ Stack Technique

- **Big Data :** Apache Spark (PySpark 3.5.0)
- **ML :** Scikit-learn + Spark MLlib
- **Visualisation :** Matplotlib, Seaborn, Plotly
- **Format :** Parquet (optimisÃ© Big Data)
- **Orchestration :** Docker + Jupyter Lab
- **Langage :** Python 3.11
- **Runtime :** Java 21 (requis pour Spark)

## ğŸ“¦ Datasets et StratÃ©gie de DonnÃ©es

### Phase 1 - POC Petite Couronne (~2.4 GB)

| Dataset | Taille | UtilitÃ© | Justification scientifique |
|---------|--------|---------|----------------------------|
| **Ã‰lections agrÃ©gÃ©es 1999-2024** | 2.2 GB | Variable cible | Historique Ã©lectoral complet toutes Ã©lections |
| **Revenus par commune** | 4.8 MB | Vote Ã©conomique | Revenu mÃ©dian = prÃ©dicteur fort (sociologie Ã©lectorale) |
| **Population historique 1968-2022** | 40 MB | Dynamique urbaine | Croissance/dÃ©clin = indicateur dynamisme commune |
| **DiplÃ´mes et formation 2022** | 81 MB | Vote culturel | Niveau Ã©ducation = variable de rÃ©fÃ©rence (ouverture/fermeture) |
| **CSP actifs 25-54 ans** | 28.5 MB | Vote de classe | Ouvriers â‰  Cadres (vote professionnel) |

â†’ **Les 3 variables socio-Ã©conomiques classiques** : Revenus + DiplÃ´mes + CSP

### Phase 2 - Extension France EntiÃ¨re (~140 MB)

| Dataset | Taille | UtilitÃ© pour France entiÃ¨re |
|---------|--------|-----------------------------|
| **Comptes communaux 2022** | 50 MB | DiversitÃ© finances locales (rural â‰  urbain) |
| **Catastrophes naturelles GASPAR** | 34.5 MB | Exposition risques environnementaux (littoral, montagne) |
| **Risques GASPAR** | variable | Perception des risques |
| **Naissances/DÃ©cÃ¨s 2008-2024** | 48 MB | Vieillissement fin (communes retraitÃ©s â‰  jeunes familles) |

â†’ **Capture la diversitÃ© territoriale** pour scalabilitÃ© 35K communes

### RÃ©fÃ©rentiel Transversal

| Dataset | Taille | UtilitÃ© |
|---------|--------|---------|
| **COG - RÃ©fÃ©rentiel communes** | 3 MB | ClÃ© de jointure (codes INSEE, dÃ©partements, rÃ©gions) |

ğŸ“‹ **Documentation complÃ¨te** :
- [DATASETS.md](docs/DATASETS.md) - Liste exhaustive avec mÃ©tadonnÃ©es
- [DOWNLOAD_PRIORITY.md](docs/DOWNLOAD_PRIORITY.md) - StratÃ©gie progressive par phases
- [URLS_DATASETS.md](docs/URLS_DATASETS.md) - URLs corrigÃ©es et stables

## ğŸ“š Documentation ComplÃ¨te

- ğŸ“– **[README.md](README.md)** (ce fichier) - Vue d'ensemble et dÃ©marrage rapide
- ğŸ—ï¸ **[ARCHITECTURE.md](docs/ARCHITECTURE.md)** - Architecture dÃ©taillÃ©e, choix techniques et bonnes pratiques
- ğŸ“Š **[DATASETS.md](docs/DATASETS.md)** - Catalogue exhaustif des datasets avec mÃ©tadonnÃ©es
- ğŸ¯ **[DOWNLOAD_PRIORITY.md](docs/DOWNLOAD_PRIORITY.md)** - StratÃ©gie de tÃ©lÃ©chargement par phases
- ğŸ”— **[URLS_DATASETS.md](docs/URLS_DATASETS.md)** - URLs de tÃ©lÃ©chargement corrigÃ©es et stables

## ğŸ‘¥ Ã‰quipe

Projet MSPR TPRE813 - EPSI 2026

---

**DerniÃ¨re mise Ã  jour** : 10 fÃ©vrier 2026
